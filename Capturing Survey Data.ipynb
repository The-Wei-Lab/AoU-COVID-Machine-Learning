{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System packages\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "from datetime import tzinfo, timedelta, datetime, date\n",
    "\n",
    "# Data storage and management\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.cbook as cbook\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotnine -- ggplot analog\n",
    "import plotnine\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the google bucket\n",
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFromBucket(name_of_file_in_bucket):\n",
    "    # get the bucket name\n",
    "    my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "    # copy csv file from the bucket to the current working space\n",
    "    os.system(f\"gsutil cp '{my_bucket}/data/{name_of_file_in_bucket}' .\")\n",
    "\n",
    "    print(f'[INFO] {name_of_file_in_bucket} is successfully downloaded into your working space')\n",
    "    # save dataframe in a csv file in the same workspace as the notebook\n",
    "    my_dataframe = pd.read_csv(name_of_file_in_bucket)\n",
    "    return my_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storeInBucket(name_of_file_loc):\n",
    "    # get the bucket name\n",
    "    \n",
    "    # This snippet assumes you run setup first\n",
    "\n",
    "    # This code saves your dataframe into a csv file in a \"data\" folder in Google Bucket\n",
    "\n",
    "    # Replace df with THE NAME OF YOUR DATAFRAME\n",
    "    my_dataframe = pd.read_csv(name_of_file_loc)   \n",
    "\n",
    "    # Replace 'test.csv' with THE NAME of the file you're going to store in the bucket (don't delete the quotation marks)\n",
    "    destination_filename = name_of_file_loc\n",
    "\n",
    "    ########################################################################\n",
    "    ##\n",
    "    ################# DON'T CHANGE FROM HERE ###############################\n",
    "    ##\n",
    "    ########################################################################\n",
    "\n",
    "    # save dataframe in a csv file in the same workspace as the notebook\n",
    "    my_dataframe.to_csv(destination_filename, index=False)\n",
    "\n",
    "    # get the bucket name\n",
    "    my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "    # copy csv file to the bucket\n",
    "    args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "    output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "    # print output from gsutil\n",
    "    output.stderr\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a representation of the Workspace's connection to the AoU Curated Data Repository\n",
    "WORKSPACE_CDR = os.getenv('WORKSPACE_CDR')\n",
    "# Get the associated GOOGLE_PROJECT billing\n",
    "MY_BILLING = os.getenv(\"GOOGLE_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date of first COVID-19 case reported in the United States\n",
    "FIRST_COVID_DX_DATE_IN_US = \"2020-01-20 00:00:00\"\n",
    "\n",
    "# Concept IDs for \"Positive\" or \"Detected\"\n",
    "CONCEPT_IDS_POS = [9191, 4126681, 45877985, 45884084, 36032716, 36715206]\n",
    "\n",
    "\n",
    "# Concept IDs for qualifying COVID-19 condition codes (ICD-10-CM U07.1 or OMOP COVID concept)\n",
    "COVID_CONDITION_LIST = [702953, 37311061]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find all the different types of COVID-related laboratory tests available in AoU dataset by searching the MEASUREMENT table for lab tests with different variations on 'SARS-CoV-2' or 'COVID'.\n",
    "\n",
    "There are a few records for tests that appear to be combined SARS-CoV-2 and Influenza PCRs. Without a clear way to differentiate what a 'Positive' result means for those tests, we will exclude those records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of COVID related measurements and their results in the dataset\n",
    "query = f\"\"\"\n",
    "    SELECT\n",
    "        concept.concept_name\n",
    "        , concept.concept_id\n",
    "        , concept.vocabulary_id\n",
    "        , concept.concept_class_id\n",
    "        , concept.concept_code\n",
    "        , m.value_source_value\n",
    "        , m.value_as_concept_id\n",
    "        , result_concepts.concept_name AS result\n",
    "        , COUNT(DISTINCT measurement_id) AS num_measurements\n",
    "        , COUNT(DISTINCT person_id) AS num_person\n",
    "    FROM\n",
    "        {WORKSPACE_CDR}.`measurement` AS m\n",
    "    INNER JOIN\n",
    "        {WORKSPACE_CDR}.`concept` AS concept\n",
    "        ON concept.concept_id = m.measurement_concept_id\n",
    "    LEFT JOIN\n",
    "        {WORKSPACE_CDR}.`concept` AS result_concepts\n",
    "        ON result_concepts.concept_id = m.value_as_concept_id\n",
    "    WHERE\n",
    "        /* 'SARS-CoV-2' or 'COVID' related measurements */\n",
    "        (\n",
    "            LOWER(concept.concept_name) like '%sars-cov-2%'\n",
    "            OR LOWER(concept.concept_name) like '%sars-cov2%'\n",
    "            OR LOWER(concept.concept_name) like '%sarscov-2%'\n",
    "            OR LOWER(concept.concept_name) like '%sarscov2%'\n",
    "            OR LOWER(concept.concept_name) like '%covid%'\n",
    "        )\n",
    "    AND /* Not a combined SARS-CoV-2 & Influenza panel */\n",
    "        (\n",
    "            LOWER(concept.concept_name) not like '%influenz%'\n",
    "        )\n",
    "    AND /* Test type of interest */\n",
    "        (\n",
    "            /* Nucleic acid amplification tests (NAAT) and other PCR / nucleic acid tests */\n",
    "            LOWER(concept.concept_name) like '%naa%'\n",
    "            OR LOWER(concept.concept_name) like '%rna%'\n",
    "            OR LOWER(concept.concept_name) like '%dna%'\n",
    "            OR LOWER(concept.concept_name) like '%nucleic acid%'\n",
    "\n",
    "            /*  Can also include antigent tests for sensitivity analysis, but sample size is smaller */\n",
    "            OR LOWER(concept.concept_name) like '%antigen%'\n",
    "            OR LOWER(concept.concept_name) like '% ag %'     \n",
    "        )\n",
    "    GROUP BY \n",
    "        concept.concept_name\n",
    "        , concept.concept_id\n",
    "        , concept.vocabulary_id\n",
    "        , concept.concept_class_id\n",
    "        , concept.concept_code\n",
    "        , m.value_source_value\n",
    "        , m.value_as_concept_id\n",
    "        , result\n",
    "\"\"\"\n",
    "\n",
    "# Query database and download data\n",
    "df = pd.read_gbq(query, dialect=\"standard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then get the CONCEPT_IDs for these SARS-CoV-2 tests using the data we pulled from the MEASUREMENT table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of the CO SARS-CoV-2 tests in measurement table: \n",
    "COVID_TEST_CONCEPT_IDS = df.loc[:, 'concept_id'].unique()\n",
    "# Alternative hard-coded list (for reproducibility)\n",
    "# COVID_TEST_CONCEPT_IDS = [706163, 706170, 700360, 706169, 706160, 704059, 706158, 723478, 706161, 586524, 723476, 586526, 706173, 715272, 742219]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Help function for plotting number of participants positive for COVID-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Help function for plotting number of participants positive for COVID-19\n",
    "def plot_positive_result_histogram(plt_data, plot_title_text=\"\", x_var=\"event_datetime\", xlab=\"\", ylab=\"\",\n",
    "                                   date_limits = [date.fromisoformat('2020-02-01'), date.fromisoformat('2022-02-15')],\n",
    "                                   label_data_string=None, date_breaks=\"2 months\"):\n",
    "    # Set up plot features\n",
    "    bar_color = \"white\"\n",
    "\n",
    "    # X-axis text\n",
    "    axis_text_x_size = 12\n",
    "    axis_text_x_hjust = 1\n",
    "    axis_text_x_angle = 30\n",
    "    axis_text_x = element_text(size=axis_text_x_size, angle=axis_text_x_angle, hjust=axis_text_x_hjust)\n",
    "\n",
    "    # Y-axis text\n",
    "    axis_text_y_size = axis_text_x_size\n",
    "    axis_text_y = element_text(size=axis_text_y_size)\n",
    "\n",
    "    # Plot title text\n",
    "    plot_title_size = 16\n",
    "    plot_title = element_text(size=plot_title_size)\n",
    "\n",
    "    # 2-week bins on x-axis\n",
    "    x_bins = pd.date_range(start=date_limits[0], end=date_limits[1], freq='SMS')\n",
    "\n",
    "    # Expand the x-axis by 14 units on the upper limit\n",
    "    x_expand = (0, 0, 0, 14)\n",
    "    # Expand the y-axis by 25% multiplication on the upper limit\n",
    "    y_expand = (0, 0, 0.25, 0)\n",
    "\n",
    "    # Data for labels\n",
    "    # If label is missing, use the number of unique person_id in plot data\n",
    "    if label_data_string is None:\n",
    "        label_data_string = f\"N: {plt_data.loc[:, 'person_id'].unique().shape[0]:,}\"\n",
    "    # Figure out what is the largest histogram bin height using the numpy.histogram function\n",
    "    hist, bin_edges = np.histogram(a=plt_data.loc[:, x_var].values.astype(np.int64), bins=x_bins.values.astype(np.int64))\n",
    "    # Use the highest histogram height, rounded up to nearest 200\n",
    "    label_y = np.ceil(np.max(hist) / 200) * 200\n",
    "    label_data = pd.DataFrame(data={'x':x_bins[2], 'y':label_y, 'label':label_data_string}, index=[0])\n",
    "    label_size = 10\n",
    "    label_pt = label_size\n",
    "\n",
    "    # Save plot\n",
    "    plot = ggplot(data=plt_data, mapping=aes(x=x_var)) + \\\n",
    "        geom_histogram(color=bar_color, breaks=x_bins) + \\\n",
    "        scale_x_datetime(date_labels=\"%b-%Y\", date_breaks = date_breaks, limits=date_limits, expand=x_expand) + \\\n",
    "        scale_y_continuous(expand = y_expand) + \\\n",
    "        labs(x=xlab, y=ylab, title=plot_title_text) + \\\n",
    "        theme_bw() + \\\n",
    "        theme(axis_text_x = axis_text_x\n",
    "              , axis_text_y = axis_text_y\n",
    "              , plot_title = plot_title)\n",
    "    \n",
    "    plot = plot + geom_label(mapping=aes(x='x', y='y', label='label'), data=label_data, ha='left')\n",
    "    # Return plot\n",
    "    return(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data retrieval\n",
    "Retreive records for SARS-CoV-2 cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "/* Demographics data */\n",
    "    SELECT\n",
    "        person.person_id\n",
    "        , person.gender_concept_id\n",
    "        , p_gender_concept.concept_name as gender\n",
    "        , person.birth_datetime as date_of_birth\n",
    "        , person.race_concept_id\n",
    "        , p_race_concept.concept_name as race\n",
    "        , person.ethnicity_concept_id\n",
    "        , p_ethnicity_concept.concept_name as ethnicity\n",
    "        , person.sex_at_birth_concept_id\n",
    "        , p_sex_at_birth_concept.concept_name as sex_at_birth \n",
    "        , event_datetime\n",
    "        , event_type\n",
    "        , event_concept_id\n",
    "        , event_name\n",
    "        , 'TRUE' as covid_positive\n",
    "    FROM\n",
    "        {WORKSPACE_CDR}.`person` person \n",
    "    LEFT JOIN\n",
    "        {WORKSPACE_CDR}.`concept` p_gender_concept \n",
    "        ON person.gender_concept_id = p_gender_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        {WORKSPACE_CDR}.`concept` p_race_concept \n",
    "        ON person.race_concept_id = p_race_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        {WORKSPACE_CDR}.`concept` p_ethnicity_concept \n",
    "        ON person.ethnicity_concept_id = p_ethnicity_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        {WORKSPACE_CDR}.`concept` p_sex_at_birth_concept \n",
    "        ON person.sex_at_birth_concept_id = p_sex_at_birth_concept.concept_id  \n",
    "    INNER JOIN (\n",
    "        /* COVID-positive by a lab test result (measurement table) */\n",
    "        SELECT\n",
    "                m.person_id as person_id\n",
    "                , m.measurement_datetime as event_datetime\n",
    "                , 'measurement' as event_type\n",
    "                , m.measurement_concept_id as event_concept_id\n",
    "                , m_concept.concept_name as event_name\n",
    "        FROM\n",
    "            {WORKSPACE_CDR}.`measurement` AS m\n",
    "        INNER JOIN\n",
    "            {WORKSPACE_CDR}.`concept` AS m_concept\n",
    "            ON m_concept.concept_id = m.measurement_concept_id\n",
    "        LEFT JOIN\n",
    "            {WORKSPACE_CDR}.`concept` AS result_concepts\n",
    "            ON result_concepts.concept_id = m.value_as_concept_id\n",
    "        WHERE\n",
    "        /* SARS-CoV-2 lab tests tests */\n",
    "            (\n",
    "                /* m.measurement_concept_id in (706163,706170,700360,706169,706160,704059,723476,706158,757685,723478,723477,706161,586524,586526,715261,742224,742218,715272,36032419,706173,757677,723464)\n",
    "                */\n",
    "                m.measurement_concept_id in ({','.join([str(x) for x in COVID_TEST_CONCEPT_IDS])})\n",
    "            )\n",
    "        AND \n",
    "        /* Test result is 'Positive' or 'Detected' */\n",
    "            (\n",
    "                /* m.value_as_concept_id in (9191,4126681,45877985,45884084,36032716,36715206)\n",
    "                */\n",
    "                m.value_as_concept_id in ({','.join([str(x) for x in CONCEPT_IDS_POS])})\n",
    "\n",
    "            )\n",
    "        \n",
    "        AND \n",
    "        /* Ensure date of the test is plausible: i.e. after date of first case in the United States */\n",
    "        /*  m.measurement_datetime >= TIMESTAMP('2020-01-20 00:00:00') */\n",
    "            m.measurement_datetime >= TIMESTAMP('{FIRST_COVID_DX_DATE_IN_US}')\n",
    "    UNION ALL\n",
    "        /* COVID-positive by a diagnosis code (condition_occurrence table) */\n",
    "        SELECT\n",
    "            co.person_id as person_id\n",
    "            , co.condition_start_datetime as event_datetime\n",
    "            , 'condition' as event_type\n",
    "            , co.condition_concept_id as event_concept_id\n",
    "            , co_concept.concept_name as event_name\n",
    "        FROM \n",
    "             {WORKSPACE_CDR}.`condition_occurrence` AS co\n",
    "        INNER JOIN\n",
    "            {WORKSPACE_CDR}.`concept` AS co_concept\n",
    "            ON co_concept.concept_id = co.condition_concept_id\n",
    "        WHERE\n",
    "        /* Presence of relevant COVID-19 diagnoses code either as condition_source_concept_id or condition_concept_id */\n",
    "            (\n",
    "                co.condition_source_concept_id IN (702953, 37311061)\n",
    "                OR co.condition_concept_id IN (702953, 37311061)\n",
    "            )\n",
    "         AND \n",
    "         /* Ensure date of the diagnosis code is plausible: i.e. after date of first case in the United States */\n",
    "         /* co.condition_start_datetime >= TIMESTAMP('2020-01-20 00:00:00') */\n",
    "            co.condition_start_datetime >= TIMESTAMP('{FIRST_COVID_DX_DATE_IN_US}')\n",
    "    UNION ALL\n",
    "        /* Self-reported COVID-positive by COPE survey (ds_survey table) */\n",
    "        SELECT\n",
    "            answer.person_id as person_id\n",
    "            , answer.survey_datetime as event_datetime\n",
    "            , 'survey' as event_type\n",
    "            , answer.survey_version_concept_id as event_concept_id\n",
    "            , answer.survey_version_name as event_name\n",
    "        FROM\n",
    "             {WORKSPACE_CDR}.`ds_survey` answer   \n",
    "        WHERE\n",
    "            /* Validation check to ensure the question_concept_id is a valid survey-related concept_id */\n",
    "            question_concept_id IN (\n",
    "                SELECT\n",
    "                    DISTINCT(question_concept_id) as concept_id  \n",
    "                FROM\n",
    "                     {WORKSPACE_CDR}.`ds_survey` \n",
    "                )\n",
    "        AND \n",
    "            /* question_concept_id for 'Was the test for COVID-19 positive?' */\n",
    "            question_concept_id IN (1333326)\n",
    "        AND\n",
    "            /* answer_concept_id indicating test result was 'Yes' or 'Yes,some' */\n",
    "            answer_concept_id IN (1332898, 1310131) \n",
    "    ) AS covid_positive\n",
    "    USING(person_id)\n",
    "    ;\n",
    "\"\"\"\n",
    "\n",
    "# Query database and download data\n",
    "df = pd.read_gbq(query, dialect=\"standard\")\n",
    "\n",
    "# Column names for database pull results\n",
    "covid_pos = 'covid_pos'\n",
    "person_id = 'person_id'\n",
    "event_type = 'event_type'\n",
    "event_datetime = 'event_datetime'\n",
    "event_name = 'event_name'\n",
    "covid_positive = 'covid_positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display number of participants\n",
    "print(f\"Number of participants with \\u2265 1 positive SARS-CoV-2 laboratory test: {df.loc[:, person_id].unique().shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of COVID-19 positive participants in AoU over time by ascertainment method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = [8, 2]\n",
    "for group in df.loc[:, event_type].unique():\n",
    "    plt_data = df.loc[df[event_type] == group, [person_id, event_datetime]].groupby([person_id]).agg(np.min).reset_index()\n",
    "    label_data_string = f\"AoU participants COVID-19 positive by {group} data: {plt_data.shape[0]:,}\"\n",
    "    tmp = plot_positive_result_histogram(plt_data=plt_data, label_data_string=label_data_string)\n",
    "    tmp = tmp + theme(figure_size = figsize)\n",
    "    print(tmp)\n",
    "    del plt_data, label_data_string, tmp\n",
    "\n",
    "plt_data = df.loc[:, [person_id, event_datetime]].groupby([person_id]).agg(np.min).reset_index()\n",
    "label_data_string = f\"AoU participants COVID-19 positive by any method: {plt_data.shape[0]:,}\"\n",
    "plot = plot_positive_result_histogram(plt_data=plt_data, label_data_string=label_data_string)\n",
    "plot = plot + theme(figure_size = figsize)\n",
    "print(plot)\n",
    "del plot, plt_data, label_data_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPI Survey and COPE Survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell takes like 5 minutes to run btw\n",
    "query = f\"\"\"\n",
    "    SELECT\n",
    "        answer.person_id,\n",
    "        answer.survey_datetime,\n",
    "        answer.survey,\n",
    "        answer.question_concept_id,\n",
    "        answer.question,\n",
    "        answer.answer_concept_id,\n",
    "        answer.answer,\n",
    "        answer.survey_version_concept_id,\n",
    "        answer.survey_version_name  \n",
    "    FROM\n",
    "         {WORKSPACE_CDR}.`ds_survey` answer   \n",
    "    WHERE\n",
    "        (\n",
    "            /* Validation check to ensure the question_concept_id is a valid survey-related concept_id */\n",
    "            question_concept_id IN (\n",
    "                SELECT\n",
    "                    DISTINCT(question_concept_id) as concept_id  \n",
    "                FROM\n",
    "                     {WORKSPACE_CDR}.`ds_survey` \n",
    "            )\n",
    "        )  \n",
    "            /* Participants in the AoU COVID-19 cohort */\n",
    "    AND (\n",
    "            answer.person_id IN ({','.join(df.loc[:, person_id].unique().astype(str))})\n",
    "        )\n",
    "        ;\n",
    "    \"\"\"\n",
    "# Query database and download data\n",
    "survey_data = pd.read_gbq(query, dialect=\"standard\")\n",
    "\n",
    "# Column names in survey data\n",
    "question = 'question'\n",
    "question_concept_id = 'question_concept_id'\n",
    "answer_concept_id = 'answer_concept_id'\n",
    "answer = 'answer'\n",
    "survey = 'survey'\n",
    "survey_datetime = 'survey_datetime'\n",
    "survey_version_concept_id = 'survey_version_concept_id'\n",
    "survey_version_name = 'survey_version_name'\n",
    "\n",
    "# Add a \"Default\" values for survey_version_name, survey_version_concept_id\n",
    "survey_data.fillna(value={survey_version_name: 'PPI', survey_version_concept_id: 0}, inplace=True, downcast='infer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Response rates for PPI survey questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of distinct Participants\n",
    "COUNT_COL = person_id\n",
    "# For each question, across each survey type\n",
    "GROUP_COLS = [survey, survey_version_name, survey_version_concept_id, question, question_concept_id]\n",
    "NUNIQUE = 'nunique'\n",
    "PROPORTION = 'proportion'\n",
    "# Unique column name suffixes for joins\n",
    "MERGE_SUFFIXES=[\"_total\", \"_skip\", '_survey']\n",
    "\n",
    "# Number of participants who responded to each survey\n",
    "survey_response = survey_data.loc[:, [person_id, survey_version_name, survey_version_concept_id]\n",
    "               ].groupby([survey_version_name, survey_version_concept_id]\n",
    "                ).agg(\n",
    "                    **{NUNIQUE+MERGE_SUFFIXES[2]: pd.NamedAgg(column=COUNT_COL, aggfunc=NUNIQUE)}\n",
    "                )\n",
    "\n",
    "# Distinct participants for each question\n",
    "survey_counts = survey_data.loc[:, [COUNT_COL] + GROUP_COLS].groupby(GROUP_COLS, dropna=False\n",
    "                          ).agg(\n",
    "                                # This dictionary unpacking (**kwards) sends 'nunique' as a keyword and pd.NamedAgg(...) as a value to 'agg' method\n",
    "                                **{NUNIQUE: pd.NamedAgg(column=COUNT_COL, aggfunc=NUNIQUE)}\n",
    "                                # {COUNT_COL: \"nunique\"}\n",
    "                               ).sort_values(NUNIQUE, ascending=False)\n",
    "\n",
    "# Number of participants who's answer was \"Skip\" for each question\n",
    "survey_counts = survey_counts.join(survey_data.loc[survey_data[answer].str.contains(\"PMI: Skip\")\n",
    "                                     , [COUNT_COL] + GROUP_COLS].groupby(GROUP_COLS, dropna=False\n",
    "                            ).agg(\n",
    "                                # This dictionary unpacking (**kwards) sends 'nunique' as a keyword and pd.NamedAgg(...) as a value to 'agg' method\n",
    "                                **{NUNIQUE: pd.NamedAgg(column=COUNT_COL, aggfunc=NUNIQUE)}\n",
    "                                # {COUNT_COL: \"nunique\"}\n",
    "                            ).sort_values(NUNIQUE, ascending=False\n",
    "                            )\n",
    "                  , how='left', lsuffix=MERGE_SUFFIXES[0], rsuffix=MERGE_SUFFIXES[1])\n",
    "\n",
    "\n",
    "# Add in number of participants who responded to each survey\n",
    "survey_counts = survey_counts.join(survey_response)\n",
    "\n",
    "# Set 'nunique_skip' to pd.Int64Dtype() to allow 'missing' integer value\n",
    "survey_counts[NUNIQUE+MERGE_SUFFIXES[1]] = survey_counts[NUNIQUE+MERGE_SUFFIXES[1]].astype(pd.Int64Dtype())\n",
    "\n",
    "# Calculate proportion of COVID-19 positive participants who answered each question \n",
    "survey_counts[PROPORTION+MERGE_SUFFIXES[0]] = survey_counts[NUNIQUE+MERGE_SUFFIXES[0]] / survey_data[person_id].unique().shape[0]\n",
    "\n",
    "# Calculate proportion of COVID-19 positive participants whose answer for each question was \"PMI: Skip\"\n",
    "survey_counts[PROPORTION+MERGE_SUFFIXES[1]] = survey_counts[NUNIQUE+MERGE_SUFFIXES[1]] / survey_counts[NUNIQUE+MERGE_SUFFIXES[0]]\n",
    "\n",
    "# Calculate response rate for each question versus total number of participants for each survey\n",
    "survey_counts[PROPORTION+MERGE_SUFFIXES[2]] = survey_counts[NUNIQUE+MERGE_SUFFIXES[0]] / survey_counts[NUNIQUE+MERGE_SUFFIXES[2]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPI survey questions with high response rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of distinct Participants\n",
    "COUNT_COL = person_id\n",
    "# For each question, across each survey type\n",
    "GROUP_COLS = [survey, survey_version_name, survey_version_concept_id, question, question_concept_id]\n",
    "\n",
    "\n",
    "# Set of key, value pairs to sort the survey questions\n",
    "survey_key_levels = {'The Basics': 0, \"Lifestyle\": 1, 'Overall Health': 2, 'Family History': 3\n",
    "                    , 'Personal Medical History': 4, 'Healthcare Access & Utilization': 5\n",
    "                    , 'Social Determinants of Health': 6}\n",
    "\n",
    "# Response rate cutoff\n",
    "RESPONSE_CUTOFF = 0.80\n",
    "# Get the question_concept_ids with good response rates, sorted by what part of the survey they are in\n",
    "question_ids_high_response_rate = \\\n",
    "    survey_counts.loc[pd.IndexSlice[:, 0, :, :, survey_counts[PROPORTION+\"_survey\"].ge(RESPONSE_CUTOFF)]\n",
    "                      , :].index.to_frame(index=False\n",
    "                                     ).sort_values(by=question_concept_id, ascending=False\n",
    "                                     ).sort_values(by='survey', key=lambda x: x.map(survey_key_levels)\n",
    "                                     )[question_concept_id]\n",
    "\n",
    "# Show the questions with high resonse rates\n",
    "survey_counts.loc[pd.IndexSlice[:, 0, :, :, survey_counts[PROPORTION+\"_survey\"].ge(RESPONSE_CUTOFF)]\n",
    "                                , :\n",
    "                 ].reset_index().loc[:, [survey, question, question_concept_id] + [NUNIQUE+s for s in MERGE_SUFFIXES[0:2]] + [PROPORTION+s for s in MERGE_SUFFIXES]\n",
    "                                    ].sort_values(by=survey, key=lambda x: x.map(survey_key_levels)\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_counts.loc[pd.IndexSlice[:, 0, :, :, survey_counts[PROPORTION+\"_survey\"].ge(RESPONSE_CUTOFF)]\n",
    "                                , :\n",
    "                 ].reset_index().loc[:, [survey, question, question_concept_id] + [NUNIQUE+s for s in MERGE_SUFFIXES[0:2]] + [PROPORTION+s for s in MERGE_SUFFIXES]\n",
    "                                    ].sort_values(by=survey, key=lambda x: x.map(survey_key_levels)\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distributions of answers for each PPI survey question with a high response rate\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    # Plot distribution of reponses for each question with high response rate\n",
    "    for question_id in question_ids_high_response_rate:\n",
    "        # Temporary plotting data -- participant counts per answer\n",
    "        df_tmp = survey_data.loc[survey_data[question_concept_id] == question_id, [person_id, answer]\n",
    "                                ].groupby([answer], dropna=False\n",
    "                                ).agg(\n",
    "                                **{NUNIQUE: pd.NamedAgg(column=COUNT_COL, aggfunc=NUNIQUE)}\n",
    "                                ).reset_index()\n",
    "        # Sort the count data answer text such that any answers with \"PMI\" are displayed last / lowest\n",
    "        df_tmp.sort_values(by=answer, key=lambda x: x.str.contains('PMI'), inplace=True, ascending=False)\n",
    "        # Set title of plot as question text \n",
    "        tmp_question = survey_data.loc[survey_data[question_concept_id] == question_id, question].unique()[0]\n",
    "        # Include total number of responses in a text box\n",
    "        tmp_box_text = f\"Number of responses: {df_tmp[NUNIQUE].sum():,}\"\n",
    "        tmp_box_props = dict(boxstyle='round', facecolor='white', alpha=1)\n",
    "        tmp_box_position={'x':0.5, 'y':0.10}\n",
    "        # Labels of plot\n",
    "        xlabel = 'Number of respondents'\n",
    "        # Plot distribution of answers for each question\n",
    "        ax = df_tmp.plot.barh(x=answer, y=NUNIQUE, title=tmp_question, legend=False, xlabel='')\n",
    "        ax.text(**tmp_box_position, s=tmp_box_text, transform=ax.transAxes, fontsize=10, verticalalignment='top', bbox=tmp_box_props)\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_ylabel('')\n",
    "\n",
    "        del ax, df_tmp, tmp_question, tmp_box_text, tmp_box_props, tmp_box_position, xlabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPI survery question encoding\n",
    "Make binary scales for 'Yes'/'No' survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to map 'yes'/'no' to 0 and 1\n",
    "binary2map = {'yes': 1, 'no': 0}\n",
    "\n",
    "# Add binary_score column for records with relevant answers by extracting the word after \":\" in answers\n",
    "BINARY_SCORE = 'binary_score'\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    survey_data[BINARY_SCORE] = survey_data.loc[survey_data[answer].str.contains('\\w+: (yes|no)$', flags=re.I) &\n",
    "                                            survey_data[question_concept_id].isin(question_ids_high_response_rate)\n",
    "                                            , answer\n",
    "                                           ].str.extract(pat='\\w+:\\s+(.+)', flags=re.I, expand=False\n",
    "                                           ).str.lower().map(binary2map).astype(pd.Int64Dtype())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert income levels into an ordinal scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names\n",
    "idx = 'idx'\n",
    "jdx = 'jdx'\n",
    "INCOME_LEVEL = 'income_level'\n",
    "\n",
    "# Possible income value answers\n",
    "INCOME_QUESTION_CONCEPT_ID = 1585375\n",
    "income_values = survey_data.loc[survey_data[question_concept_id].isin([INCOME_QUESTION_CONCEPT_ID])\n",
    "                , answer]\n",
    "\n",
    "# Extract income numbers and sort numerically. Replace 'less 10k' with '0k' and 'more 200k' with '200k'\n",
    "tmp = income_values.str.replace(r'less', '0k', regex=True\n",
    "     ).str.replace(r'more', '200k', regex=True\n",
    "     ).str.extract(r'annual income: (?P<income_level>\\d+k)', flags=re.I, expand=True\n",
    "     ).assign(**{idx:lambda x: x[INCOME_LEVEL].str.extract('(\\d+)k', expand=False).astype(float)}\n",
    "     ).sort_values(by=idx, ascending=True\n",
    "     )\n",
    "# Use groupby.ngroup to count number of distinct 'income_level' groups, sorted numerically, to get an ordinal scale\n",
    "tmp[jdx] = tmp.groupby(idx).ngroup() + 1\n",
    "tmp.loc[tmp[INCOME_LEVEL].isna(), jdx] = np.nan\n",
    "# Export ordinal scale for income_level to a dictionary mapper\n",
    "income_mapper = tmp.loc[:, [INCOME_LEVEL, jdx]].drop_duplicates().set_index(INCOME_LEVEL).to_dict()[jdx]\n",
    "del tmp\n",
    "\n",
    "# Transform the income level into an ordinal scale\n",
    "survey_data[INCOME_LEVEL] = survey_data.loc[survey_data[question_concept_id].isin([INCOME_QUESTION_CONCEPT_ID])\n",
    "                                            , answer\n",
    "                                           ].str.replace(r'less', '0k', regex=True\n",
    "                                           ).str.replace(r'more', '200k', regex=True\n",
    "                                           ).str.extract(r'annual income: (?P<income_level>\\d+k)', flags=re.I, expand=False\n",
    "                                           ).map(income_mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert education levels into an ordinal scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal scale education level mapper\n",
    "education7map = {\n",
    "    'Never Attended':1\n",
    "    ,'One Through Four':2\n",
    "    ,'Five Through Eight':3\n",
    "    ,'Nine Through Eleven':4\n",
    "    ,'Twelve Or GED':5\n",
    "    ,'College One to Three':6\n",
    "    ,'College Graduate':7\n",
    "    ,'Advanced Degree':8\n",
    "    , np.nan: 0\n",
    "}\n",
    "\n",
    "# Column name\n",
    "EDUCATION_LEVEL = 'education_level'\n",
    "EDUCATION_QUESTION_CONCEPT_ID = 1585940\n",
    "\n",
    "# Transform the education level into an ordinal scale\n",
    "survey_data[EDUCATION_LEVEL] = survey_data.loc[survey_data[question_concept_id].isin([EDUCATION_QUESTION_CONCEPT_ID])\n",
    "                                               , answer\n",
    "                                              ].str.extract(r'\\w+: (?P<education_level>.+)', flags=re.I, expand=False\n",
    "                                           ).map(education7map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert levels of duration in current living situation into an ordinal scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 'idx'\n",
    "\n",
    "# Possible living duration value answers and question_concept_id\n",
    "LIVING_DURATION_CONCEPT_ID = 1585879\n",
    "LIVING_DURATION = 'living_duration'\n",
    "\n",
    "# Extract living duration and sort numerically. Replace 'less' with '0' and '20' with '20'\n",
    "tmp = survey_data.loc[survey_data[question_concept_id].isin([LIVING_DURATION_CONCEPT_ID])\n",
    "                , answer\n",
    "               ].str.replace(r'less', '0', regex=True\n",
    "               ).str.replace(r'more', '20', regex=True\n",
    "               ).str.extract(r'\\w+: (?P<living_duration>\\d+)', flags=re.I, expand=True\n",
    "               ).astype(float).astype(pd.Int64Dtype()\n",
    "               ).sort_values(by=LIVING_DURATION)\n",
    "\n",
    "# Use groupby.ngroup to count number of distinct 'income_level' groups, sorted numerically, to get an ordinal scale\n",
    "tmp[idx] = tmp.groupby(LIVING_DURATION).ngroup() + 1\n",
    "tmp.loc[tmp[LIVING_DURATION].isna(), idx] = np.nan\n",
    "\n",
    "# Export ordinal scale for living_duration to a dictionary mapper\n",
    "living_duration_mapper = tmp.loc[:, [LIVING_DURATION, idx]].drop_duplicates().set_index(LIVING_DURATION).to_dict()[idx]\n",
    "del tmp\n",
    "\n",
    "# Transform the living duration into an ordinal scale\n",
    "survey_data[LIVING_DURATION] = survey_data.loc[survey_data[question_concept_id].isin([LIVING_DURATION_CONCEPT_ID])\n",
    "                                               , answer\n",
    "                                              ].str.replace(r'less', '0', regex=True\n",
    "                                              ).str.replace(r'more', '20', regex=True\n",
    "                                              ).str.extract(r'\\w+: (?P<living_duration>\\d+)', flags=re.I, expand=False\n",
    "                                              ).astype(float).astype(pd.Int64Dtype()\n",
    "                                              ).map(living_duration_mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Likert Scales for 'Overall Health' questions from text to numerical scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to map various Likert Scales to similar 5-point ordinal scale\n",
    "likert5map = {'excellent': 5, 'excllent':5, 'very good': 4, 'good': 3, 'fair': 2, 'poor': 1\n",
    "        , 'always': 5, 'often': 4, 'sometimes': 3, 'occasionally': 2, 'rarely': 2, 'never': 1\n",
    "        , 'extremely': 5, 'quite a bit': 4, 'somewhat': 3, 'a little bit': 2, 'not at all': 1\n",
    "        , 'very severe': 5, 'severe': 4, 'moderate': 3, 'mild': 2, 'none': 1\n",
    "        , 'completely': 5, 'mostly': 4, 'moderately': 3, 'a little': 2\n",
    "       }\n",
    "\n",
    "# Add likert_score column for records with relevant answers\n",
    "LIKERT_SCORE = 'likert_score'\n",
    "survey_data[LIKERT_SCORE] = survey_data.loc[survey_data[survey].eq('Overall Health')\n",
    "                                            , answer\n",
    "                                           ].str.extract(pat='\\w+:\\s+(.+)', flags=re.I, expand=False\n",
    "                                           ).str.lower(\n",
    "                                           ).map(likert5map\n",
    "                                           ).astype(pd.Int64Dtype())\n",
    "\n",
    "# Average pain  in last 7 days -- get numerical values from 0 to 10\n",
    "AVG_PAIN_QUESTION_CONCEPT_ID=1585747\n",
    "survey_data[LIKERT_SCORE] = survey_data.loc[survey_data[survey].eq('Overall Health') & \\\n",
    "                                            survey_data[question_concept_id].isin([AVG_PAIN_QUESTION_CONCEPT_ID])\n",
    "                                            , answer\n",
    "                                           ].str.extract(r'(\\d+)', flags=re.I, expand=False\n",
    "                                           ).astype(float\n",
    "                                           ).astype(pd.Int64Dtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_data.loc[survey_data[answer].str.contains('\\w+: (yes|no)$', flags=re.I) &\n",
    "                survey_data[question_concept_id].isin(question_ids_high_response_rate)\n",
    "                , answer].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT_COL = person_id\n",
    "GROUP_COLS = [question_concept_id, question, answer, answer_concept_id]\n",
    "tmp = survey_data.loc[\n",
    "    survey_data[survey].str.match('Overall Health')\n",
    "    , :\n",
    "    ].groupby(GROUP_COLS\n",
    "    ).agg(\n",
    "        **{NUNIQUE: pd.NamedAgg(column=COUNT_COL, aggfunc=NUNIQUE)}\n",
    "    ).reset_index()\n",
    "\n",
    "# Number of distinct answers per question\n",
    "GROUP_COLS = [question, question_concept_id]\n",
    "COUNT_COL = answer_concept_id\n",
    "answer_counts = tmp.loc[:, [COUNT_COL] + GROUP_COLS].groupby(GROUP_COLS).agg(\n",
    "                **{NUNIQUE: pd.NamedAgg(column=COUNT_COL, aggfunc=NUNIQUE)}\n",
    "                )\n",
    "answer_counts\n",
    "\n",
    "#\n",
    "COUNT_COL = person_id\n",
    "GROUP_COLS = [question_concept_id, question, answer, answer_concept_id]\n",
    "tmp = survey_data.loc[\n",
    "    (survey_data[question_concept_id].isin(answer_counts.loc[answer_counts[NUNIQUE].eq(6), :].index.get_level_values(1)) | \\\n",
    "     survey_data[question_concept_id].eq(1585729)) & \\\n",
    "    survey_data[question_concept_id].isin(question_ids_high_response_rate)\n",
    "    , :\n",
    "    ].groupby(GROUP_COLS\n",
    "             ).agg(\n",
    "        **{NUNIQUE: pd.NamedAgg(column=COUNT_COL, aggfunc=NUNIQUE)}\n",
    "    ).reset_index()\n",
    "\n",
    "LIKERT_SCORE = 'likert_score'\n",
    "tmp[LIKERT_SCORE] = tmp[answer].str.extract(pat='\\w+:\\s+(.+)', flags=re.I, expand=False).str.lower().map(likert5map).astype(pd.Int64Dtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smoking_questions =  survey_data.loc[survey_data[question].str.contains('smoking', flags=re.I), [question, question_id]].drop_duplicates()\n",
    "# smoking_questions\n",
    "tobacco_questions =  survey_counts.index.get_level_values(3)[\n",
    "                        survey_counts.index.get_level_values(3).to_series().str.match('Smoking:') \n",
    "                        ].values\n",
    "tobacco_question_concept_ids = survey_counts.loc[pd.IndexSlice[:, 0, :, tobacco_questions, :], :].index.get_level_values(4).values\n",
    "                   \n",
    "\n",
    "survey_data.loc[\n",
    "    survey_data[person_id].isin(\n",
    "        survey_data.loc[\n",
    "            survey_data[question_concept_id].isin([1585857]) & \\\n",
    "            survey_data[answer_concept_id].isin([1585858])\n",
    "            , person_id\n",
    "            ]\n",
    "        ) & \\\n",
    "    survey_data[question_concept_id].isin(tobacco_question_concept_ids)\n",
    " , :\n",
    "].groupby(GROUP_COLS\n",
    "                ).agg(\n",
    "                **{NUNIQUE: pd.NamedAgg(column=COUNT_COL, aggfunc=NUNIQUE)}\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# survey_data.loc[survey_data[answer_concept_id].isna(), :]\n",
    "survey_data.loc[survey_data[question_concept_id].eq(1586159), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1585864\n",
    "\n",
    "query = f\"\"\"\n",
    "    SELECT * \n",
    "    FROM\n",
    "         {WORKSPACE_CDR}.`ds_survey` answer   \n",
    "    LIMIT 1000\n",
    "        ;\n",
    "    \"\"\"\n",
    "# Query database and download data\n",
    "data = pd.read_gbq(query, dialect=\"standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset \"TESTING_COVID_DATASET\" for domain \"person\" and was generated for All of Us Controlled Tier Dataset v6\n",
    "dataset_34296773_person_sql = \"\"\"\n",
    "    SELECT\n",
    "        person.person_id,\n",
    "        person.gender_concept_id,\n",
    "        p_gender_concept.concept_name as gender,\n",
    "        person.birth_datetime as date_of_birth,\n",
    "        person.race_concept_id,\n",
    "        p_race_concept.concept_name as race,\n",
    "        person.ethnicity_concept_id,\n",
    "        p_ethnicity_concept.concept_name as ethnicity,\n",
    "        person.sex_at_birth_concept_id,\n",
    "        p_sex_at_birth_concept.concept_name as sex_at_birth \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".person` person \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_gender_concept \n",
    "            ON person.gender_concept_id = p_gender_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_race_concept \n",
    "            ON person.race_concept_id = p_race_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_ethnicity_concept \n",
    "            ON person.ethnicity_concept_id = p_ethnicity_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_sex_at_birth_concept \n",
    "            ON person.sex_at_birth_concept_id = p_sex_at_birth_concept.concept_id  \n",
    "    WHERE\n",
    "        person.PERSON_ID IN (\n",
    "            SELECT\n",
    "                distinct person_id  \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "            WHERE\n",
    "                cb_search_person.person_id IN (\n",
    "                    SELECT\n",
    "                        criteria.person_id \n",
    "                    FROM\n",
    "                        (SELECT\n",
    "                            DISTINCT person_id,\n",
    "                            entry_date,\n",
    "                            concept_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                        WHERE\n",
    "                            (\n",
    "                                concept_id IN (702953) \n",
    "                                AND is_standard = 0 \n",
    "                            )) criteria \n",
    "                    UNION\n",
    "                    ALL SELECT\n",
    "                        criteria.person_id \n",
    "                    FROM\n",
    "                        (SELECT\n",
    "                            DISTINCT person_id,\n",
    "                            entry_date,\n",
    "                            concept_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                        WHERE\n",
    "                            (\n",
    "                                concept_id IN (706163) \n",
    "                                AND is_standard = 1  \n",
    "                                AND  value_as_concept_id IN (9191, 4126681, 45877985, 45884084)\n",
    "                            )) criteria \n",
    "                    UNION\n",
    "                    ALL SELECT\n",
    "                        criteria.person_id \n",
    "                    FROM\n",
    "                        (SELECT\n",
    "                            DISTINCT person_id,\n",
    "                            entry_date,\n",
    "                            concept_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                        WHERE\n",
    "                            (\n",
    "                                concept_id IN (706170) \n",
    "                                AND is_standard = 1  \n",
    "                                AND  value_as_concept_id IN (45877985, 45884084)\n",
    "                            )) criteria \n",
    "                    UNION\n",
    "                    ALL SELECT\n",
    "                        criteria.person_id \n",
    "                    FROM\n",
    "                        (SELECT\n",
    "                            DISTINCT person_id,\n",
    "                            entry_date,\n",
    "                            concept_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                        WHERE\n",
    "                            (\n",
    "                                concept_id IN (700360) \n",
    "                                AND is_standard = 1  \n",
    "                                AND  value_as_concept_id IN (45884084, 45877985)\n",
    "                            )) criteria \n",
    "                    UNION\n",
    "                    ALL SELECT\n",
    "                        criteria.person_id \n",
    "                    FROM\n",
    "                        (SELECT\n",
    "                            DISTINCT person_id,\n",
    "                            entry_date,\n",
    "                            concept_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                        WHERE\n",
    "                            (\n",
    "                                concept_id IN (706169) \n",
    "                                AND is_standard = 1  \n",
    "                                AND  value_as_concept_id IN (45877985, 45884084)\n",
    "                            )) criteria ) \n",
    "                )\"\"\"\n",
    "\n",
    "dataset_34296773_person_df = pandas.read_gbq(\n",
    "    dataset_34296773_person_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_34296773_person_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This query represents dataset \"TESTING_COVID_DATASET\" for domain \"survey\" and was generated for All of Us Controlled Tier Dataset v6\n",
    "dataset_34296773_survey_sql = \"\"\"\n",
    "    SELECT\n",
    "        answer.person_id,\n",
    "        answer.survey_datetime,\n",
    "        answer.survey,\n",
    "        answer.question_concept_id,\n",
    "        answer.question,\n",
    "        answer.answer_concept_id,\n",
    "        answer.answer,\n",
    "        answer.survey_version_concept_id,\n",
    "        answer.survey_version_name  \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".ds_survey` answer   \n",
    "    WHERE\n",
    "        (\n",
    "            question_concept_id IN (\n",
    "                SELECT\n",
    "                    DISTINCT(question_concept_id) as concept_id  \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".ds_survey` \n",
    "            )\n",
    "        )  \n",
    "        AND (\n",
    "            answer.PERSON_ID IN (\n",
    "                SELECT\n",
    "                    distinct person_id  \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "                WHERE\n",
    "                    cb_search_person.person_id IN (\n",
    "                        SELECT\n",
    "                            criteria.person_id \n",
    "                        FROM\n",
    "                            (SELECT\n",
    "                                DISTINCT person_id,\n",
    "                                entry_date,\n",
    "                                concept_id \n",
    "                            FROM\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                            WHERE\n",
    "                                (\n",
    "                                    concept_id IN (702953) \n",
    "                                    AND is_standard = 0 \n",
    "                                )) criteria \n",
    "                        UNION\n",
    "                        ALL SELECT\n",
    "                            criteria.person_id \n",
    "                        FROM\n",
    "                            (SELECT\n",
    "                                DISTINCT person_id,\n",
    "                                entry_date,\n",
    "                                concept_id \n",
    "                            FROM\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                            WHERE\n",
    "                                (\n",
    "                                    concept_id IN (706163) \n",
    "                                    AND is_standard = 1  \n",
    "                                    AND  value_as_concept_id IN (9191, 4126681, 45877985, 45884084)\n",
    "                                )) criteria \n",
    "                        UNION\n",
    "                        ALL SELECT\n",
    "                            criteria.person_id \n",
    "                        FROM\n",
    "                            (SELECT\n",
    "                                DISTINCT person_id,\n",
    "                                entry_date,\n",
    "                                concept_id \n",
    "                            FROM\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                            WHERE\n",
    "                                (\n",
    "                                    concept_id IN (706170) \n",
    "                                    AND is_standard = 1  \n",
    "                                    AND  value_as_concept_id IN (45877985, 45884084)\n",
    "                                )) criteria \n",
    "                        UNION\n",
    "                        ALL SELECT\n",
    "                            criteria.person_id \n",
    "                        FROM\n",
    "                            (SELECT\n",
    "                                DISTINCT person_id,\n",
    "                                entry_date,\n",
    "                                concept_id \n",
    "                            FROM\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                            WHERE\n",
    "                                (\n",
    "                                    concept_id IN (700360) \n",
    "                                    AND is_standard = 1  \n",
    "                                    AND  value_as_concept_id IN (45884084, 45877985)\n",
    "                                )) criteria \n",
    "                        UNION\n",
    "                        ALL SELECT\n",
    "                            criteria.person_id \n",
    "                        FROM\n",
    "                            (SELECT\n",
    "                                DISTINCT person_id,\n",
    "                                entry_date,\n",
    "                                concept_id \n",
    "                            FROM\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                            WHERE\n",
    "                                (\n",
    "                                    concept_id IN (706169) \n",
    "                                    AND is_standard = 1  \n",
    "                                    AND  value_as_concept_id IN (45877985, 45884084)\n",
    "                                )) criteria ) \n",
    "                    )\n",
    "                )\"\"\"\n",
    "\n",
    "dataset_34296773_survey_df = pandas.read_gbq(\n",
    "    dataset_34296773_survey_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_34296773_survey_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This query represents dataset \"TESTING_COVID_DATASET\" for domain \"person\" and was generated for All of Us Controlled Tier Dataset v6\n",
    "dataset_54654031_person_sql = \"\"\"\n",
    "    SELECT\n",
    "        person.person_id,\n",
    "        person.gender_concept_id,\n",
    "        p_gender_concept.concept_name as gender,\n",
    "        person.birth_datetime as date_of_birth,\n",
    "        person.race_concept_id,\n",
    "        p_race_concept.concept_name as race,\n",
    "        person.ethnicity_concept_id,\n",
    "        p_ethnicity_concept.concept_name as ethnicity,\n",
    "        person.sex_at_birth_concept_id,\n",
    "        p_sex_at_birth_concept.concept_name as sex_at_birth \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".person` person \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_gender_concept \n",
    "            ON person.gender_concept_id = p_gender_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_race_concept \n",
    "            ON person.race_concept_id = p_race_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_ethnicity_concept \n",
    "            ON person.ethnicity_concept_id = p_ethnicity_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_sex_at_birth_concept \n",
    "            ON person.sex_at_birth_concept_id = p_sex_at_birth_concept.concept_id  \n",
    "    WHERE\n",
    "        person.PERSON_ID IN (\n",
    "            SELECT\n",
    "                distinct person_id  \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "            WHERE\n",
    "                cb_search_person.person_id IN (\n",
    "                    SELECT\n",
    "                        criteria.person_id \n",
    "                    FROM\n",
    "                        (SELECT\n",
    "                            DISTINCT person_id,\n",
    "                            entry_date,\n",
    "                            concept_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                        WHERE\n",
    "                            (\n",
    "                                concept_id IN (702953) \n",
    "                                AND is_standard = 0 \n",
    "                            )) criteria \n",
    "                    UNION\n",
    "                    ALL SELECT\n",
    "                        criteria.person_id \n",
    "                    FROM\n",
    "                        (SELECT\n",
    "                            DISTINCT person_id,\n",
    "                            entry_date,\n",
    "                            concept_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                        WHERE\n",
    "                            (\n",
    "                                concept_id IN (706163) \n",
    "                                AND is_standard = 1  \n",
    "                                AND  value_as_concept_id IN (9191, 4126681, 45877985, 45884084)\n",
    "                            )) criteria \n",
    "                    UNION\n",
    "                    ALL SELECT\n",
    "                        criteria.person_id \n",
    "                    FROM\n",
    "                        (SELECT\n",
    "                            DISTINCT person_id,\n",
    "                            entry_date,\n",
    "                            concept_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                        WHERE\n",
    "                            (\n",
    "                                concept_id IN (706170) \n",
    "                                AND is_standard = 1  \n",
    "                                AND  value_as_concept_id IN (45877985, 45884084)\n",
    "                            )) criteria \n",
    "                    UNION\n",
    "                    ALL SELECT\n",
    "                        criteria.person_id \n",
    "                    FROM\n",
    "                        (SELECT\n",
    "                            DISTINCT person_id,\n",
    "                            entry_date,\n",
    "                            concept_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                        WHERE\n",
    "                            (\n",
    "                                concept_id IN (700360) \n",
    "                                AND is_standard = 1  \n",
    "                                AND  value_as_concept_id IN (45884084, 45877985)\n",
    "                            )) criteria \n",
    "                    UNION\n",
    "                    ALL SELECT\n",
    "                        criteria.person_id \n",
    "                    FROM\n",
    "                        (SELECT\n",
    "                            DISTINCT person_id,\n",
    "                            entry_date,\n",
    "                            concept_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                        WHERE\n",
    "                            (\n",
    "                                concept_id IN (706169) \n",
    "                                AND is_standard = 1  \n",
    "                                AND  value_as_concept_id IN (45877985, 45884084)\n",
    "                            )) criteria ) \n",
    "                )\"\"\"\n",
    "\n",
    "dataset_54654031_person_df = pandas.read_gbq(\n",
    "    dataset_54654031_person_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_54654031_person_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This query represents dataset \"TESTING_COVID_DATASET\" for domain \"survey\" and was generated for All of Us Controlled Tier Dataset v6\n",
    "dataset_54654031_survey_sql = \"\"\"\n",
    "    SELECT\n",
    "        answer.person_id,\n",
    "        answer.survey_datetime,\n",
    "        answer.survey,\n",
    "        answer.question_concept_id,\n",
    "        answer.question,\n",
    "        answer.answer_concept_id,\n",
    "        answer.answer,\n",
    "        answer.survey_version_concept_id,\n",
    "        answer.survey_version_name  \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".ds_survey` answer   \n",
    "    WHERE\n",
    "        (\n",
    "            question_concept_id IN (\n",
    "                SELECT\n",
    "                    DISTINCT(question_concept_id) as concept_id  \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".ds_survey` \n",
    "            )\n",
    "        )  \n",
    "        AND (\n",
    "            answer.PERSON_ID IN (\n",
    "                SELECT\n",
    "                    distinct person_id  \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "                WHERE\n",
    "                    cb_search_person.person_id IN (\n",
    "                        SELECT\n",
    "                            criteria.person_id \n",
    "                        FROM\n",
    "                            (SELECT\n",
    "                                DISTINCT person_id,\n",
    "                                entry_date,\n",
    "                                concept_id \n",
    "                            FROM\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                            WHERE\n",
    "                                (\n",
    "                                    concept_id IN (702953) \n",
    "                                    AND is_standard = 0 \n",
    "                                )) criteria \n",
    "                        UNION\n",
    "                        ALL SELECT\n",
    "                            criteria.person_id \n",
    "                        FROM\n",
    "                            (SELECT\n",
    "                                DISTINCT person_id,\n",
    "                                entry_date,\n",
    "                                concept_id \n",
    "                            FROM\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                            WHERE\n",
    "                                (\n",
    "                                    concept_id IN (706163) \n",
    "                                    AND is_standard = 1  \n",
    "                                    AND  value_as_concept_id IN (9191, 4126681, 45877985, 45884084)\n",
    "                                )) criteria \n",
    "                        UNION\n",
    "                        ALL SELECT\n",
    "                            criteria.person_id \n",
    "                        FROM\n",
    "                            (SELECT\n",
    "                                DISTINCT person_id,\n",
    "                                entry_date,\n",
    "                                concept_id \n",
    "                            FROM\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                            WHERE\n",
    "                                (\n",
    "                                    concept_id IN (706170) \n",
    "                                    AND is_standard = 1  \n",
    "                                    AND  value_as_concept_id IN (45877985, 45884084)\n",
    "                                )) criteria \n",
    "                        UNION\n",
    "                        ALL SELECT\n",
    "                            criteria.person_id \n",
    "                        FROM\n",
    "                            (SELECT\n",
    "                                DISTINCT person_id,\n",
    "                                entry_date,\n",
    "                                concept_id \n",
    "                            FROM\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                            WHERE\n",
    "                                (\n",
    "                                    concept_id IN (700360) \n",
    "                                    AND is_standard = 1  \n",
    "                                    AND  value_as_concept_id IN (45884084, 45877985)\n",
    "                                )) criteria \n",
    "                        UNION\n",
    "                        ALL SELECT\n",
    "                            criteria.person_id \n",
    "                        FROM\n",
    "                            (SELECT\n",
    "                                DISTINCT person_id,\n",
    "                                entry_date,\n",
    "                                concept_id \n",
    "                            FROM\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                            WHERE\n",
    "                                (\n",
    "                                    concept_id IN (706169) \n",
    "                                    AND is_standard = 1  \n",
    "                                    AND  value_as_concept_id IN (45877985, 45884084)\n",
    "                                )) criteria ) \n",
    "                    )\n",
    "                )\"\"\"\n",
    "\n",
    "dataset_54654031_survey_df = pandas.read_gbq(\n",
    "    dataset_54654031_survey_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_54654031_survey_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_54654031_survey_df = dataset_54654031_survey_df.sort_values('person_id', ignore_index=True)\n",
    "dataset_54654031_survey_df[dataset_54654031_survey_df['person_id']==1000453]\n",
    "#This shows that there are about 189 survey questions for each patient.\n",
    "#I think the best course of action would be to remove irrelavant questions, and quantify the rest\n",
    "#After that's done, we might be able to find the most important questions by comparing it to long Covid cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveyDf = dataset_54654031_survey_df\n",
    "surveyDf['survey'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The best thing to do here might be to focus only on the questions that have numerical outputs\n",
    "intList = range(0,101)\n",
    "ansList= ['Yes', 'No', 'yes', 'no']\n",
    "len(surveyDf[surveyDf['answer'].isin(intList)]['question'].unique())\n",
    "len(surveyDf[surveyDf['answer'].isin(ansList)]['question'].unique())\n",
    "\n",
    "#It looks like these questions have not been transformed into numeric values yet\n",
    "#Dictionaries have been created above to help with this however"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Long Covid Data and convert survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storeInBucket('ImportantQuestionsAoU.csv')\n",
    "importantQuestionDf = getFromBucket('ImportantQuestionsAoU.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets load our significant questions and long covid status in \n",
    "#To load in these files go to -> File -> Open... -> Upload\n",
    "LongCovidEHRDf = getFromBucket('n3c_aou_cohort.csv')\n",
    "LongCovidEHRDf\n",
    "\n",
    "print('Long Covid Size: ' , len(LongCovidEHRDf))            \n",
    "print('Important Question Size: ' , len(importantQuestionDf))\n",
    "longCovidDf = LongCovidEHRDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now what we want to do is filter the questions by the IDs on important question size\n",
    "importantQuestionDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveyDf = surveyDf[surveyDf[question_concept_id].isin(importantQuestionDf[question_concept_id])]\n",
    "surveyDf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have the surveys filtered, but we need to take those filtered surveys and attach them to our longCovid df\n",
    "#Each of these question Ids need to be its own column that we will add for each person\n",
    "longCovidDf = longCovidDf[longCovidDf['person_id'].isin(surveyDf['person_id'])]\n",
    "\n",
    "#Add a component that takes away the EHR data from this dataframe\n",
    "longCovidDf = longCovidDf.loc[:, ['person_id', 'y_pred', 'long_covid']]\n",
    "\n",
    "print(len(longCovidDf))\n",
    "surveyDf = surveyDf[surveyDf['person_id'].isin(longCovidDf['person_id'])]\n",
    "print(len(surveyDf))\n",
    "longCovidDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personList = longCovidDf['person_id'].unique()\n",
    "\n",
    "for question in importantQuestionDf['question'].unique():\n",
    "    #print(question)\n",
    "    longCovidDf[question] = str(\"No Answer\")\n",
    "    longCovidDf= longCovidDf.astype({question : 'str'})\n",
    "    for person in personList:\n",
    "        personDf = surveyDf.loc[surveyDf['person_id'] == person]\n",
    "        try:\n",
    "            answer = personDf.loc[personDf['question']== question ,'answer'].reset_index(drop=True)[0]\n",
    "        except KeyError:\n",
    "            answer = \"Error: Not Answered\"\n",
    "        try:\n",
    "            answer = answer.split(': ')[1]\n",
    "        except IndexError:\n",
    "            answer = answer\n",
    "            #keep the answer the same\n",
    "        longCovidDf.loc[longCovidDf['person_id'] == person, question] = answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longCovidDf= longCovidDf.reset_index(drop=True)\n",
    "for a in longCovidDf.columns:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Question Types and Making Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a List of Variables that shows the options that should be voided\n",
    "obstainOptionsList = ['Skip', \"Don't know\" , 'Prefer not to answer', 'Prefer Not To Answer','NaN', 'Dont Know',\n",
    "                      'Sex At Birth None Of These', 'Intersex', 'Not Answered', 'PMI: Skip', 'Response removed due to invalid value'\n",
    "                      'Sex At Birth None of These', 'Other Arrangement', 'Not Answered', 'No matching concept', 'Response removed due to invalid value']\n",
    "def checkObstain(answer):\n",
    "    if (answer in (obstainOptionsList)):\n",
    "        return np.NaN\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Variables (Yes-No, USA-Other, Male-Female, Rent-Own )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make List Of Options as well as their matching DictionAries\n",
    "#If the Dictionaries are Already made from Eric's Work, Copy them here\n",
    "binaryOptionList = ['Yes', 'No', 'USA', 'Other', 'Rent', 'Own', 'Male', 'Female']\n",
    "binaryMap = {'Yes': 1, 'No': 0, 'USA':1, 'Other':0, 'Rent':0, 'Own':1, 'Male':0, 'Female':1}\n",
    "binaryQuestionList = ['Overall Health: Outside Travel 6 Month','The Basics: Birthplace','Hookah Smoking: Hookah Smoke Participant',\n",
    "                     'Alcohol: Alcohol Participant','Smoking: 100 Cigs Lifetime','Active Duty: Active Duty Serve Status',\n",
    "                     'Smokeless Tobacco: Smokeless Tobacco Participant','Electronic Smoking: Electric Smoke Participant',\n",
    "                     'Cigar Smoking: Cigar Smoke Participant','Home Own: Current Home Own','Overall Health: Organ Transplant',\n",
    "                     'Insurance: Health Insurance','Living Situation: Stable House Concern','Biological Sex At Birth: Sex At Birth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for question in binaryQuestionList:\n",
    "    for i in range(0,len(longCovidDf)):\n",
    "        answer = longCovidDf.loc[i,question]\n",
    "        answer = checkObstain(answer)\n",
    "        if (answer in binaryOptionList):\n",
    "            longCovidDf.loc[i,question] = binaryMap[answer]\n",
    "        else:\n",
    "            longCovidDf.loc[i,question] = answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poor-Fair-Good-VeryGood-Excellent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodOptionList= ['Poor','Fair','Good', 'Very Good', 'Excellent', 'Excllent' ]\n",
    "goodMap = {'Poor': 1, 'Fair': 2, 'Good':3,'Very Good':4, 'Excellent':5, 'Excllent':5}\n",
    "goodQuestionList = ['Overall Health: Social Satisfaction','Overall Health: General Mental Health','Overall Health: General Social',\n",
    "                   'Overall Health: General Physical Health','Overall Health: General Quality','Overall Health: General Health']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for question in goodQuestionList:\n",
    "    for i in range(0,len(longCovidDf)):\n",
    "        answer = longCovidDf.loc[i,question]\n",
    "        answer = checkObstain(answer)\n",
    "        if (answer in goodOptionList):\n",
    "            longCovidDf.loc[i,question] = goodMap[answer]\n",
    "        else:\n",
    "            longCovidDf.loc[i,question] = answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oftenOptionList = ['Never', 'Rarely', 'Sometimes', 'Often', 'Always', 'Occasionally']\n",
    "oftenMap = {'Never':0, 'Rarely':1, 'Sometimes':2, 'Often':3,'Occasionally':3, 'Always':4}\n",
    "oftenQuestionList = ['Overall Health: Emotional Problem 7 Days','Overall Health: Difficult Understand Info','Overall Health: Health Material Assistance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for question in oftenQuestionList:\n",
    "    for i in range(0,len(longCovidDf)):\n",
    "        answer = longCovidDf.loc[i,question]\n",
    "        answer = checkObstain(answer)\n",
    "        if (answer in oftenOptionList):\n",
    "            longCovidDf.loc[i,question] = oftenMap[answer]\n",
    "        else:\n",
    "            longCovidDf.loc[i,question] = answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Severe Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severeOptionList = ['None', 'Mild', 'Moderate', 'Severe', 'Very Severe']\n",
    "severeMap = {'None':0, 'Mild':1, 'Moderate':2, 'Severe':3, 'Very Severe':4}\n",
    "severeQuestionList = ['Overall Health: Average Fatigue 7 Days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for question in severeQuestionList:\n",
    "    for i in range(0,len(longCovidDf)):\n",
    "        answer = longCovidDf.loc[i,question]\n",
    "        answer = checkObstain(answer)\n",
    "        if (answer in severeOptionList):\n",
    "            longCovidDf.loc[i,question] = severeMap[answer]\n",
    "        else:\n",
    "            longCovidDf.loc[i,question] = answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How Much it Describes You"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describeOptionList = ['Not At All', 'A Little Bit', 'Somewhat', 'Quite a Bit','Quite A Bit', 'Extremely']\n",
    "describeMap = {'Not At All':0, 'A Little Bit':1, 'Somewhat':2, 'Quite a Bit':3,'Quite A Bit':3,  'Extremely':4}\n",
    "describeQuestionList = ['Overall Health: Medical Form Confidence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for question in describeQuestionList:\n",
    "    for i in range(0,len(longCovidDf)):\n",
    "        answer = longCovidDf.loc[i,question]\n",
    "        answer = checkObstain(answer)\n",
    "        if (answer in describeOptionList):\n",
    "            longCovidDf.loc[i,question] = describeMap[answer]\n",
    "        else:\n",
    "            longCovidDf.loc[i,question] = answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe2OptionList = ['Not At All', 'A Little', 'Moderately', 'Mostly', 'Completely', 'Quite A Bit']\n",
    "describe2Map = {'Not At All':0, 'A Little':1, 'Moderately':2, 'Mostly':3,'Quite A Bit':3,  'Completely':4}\n",
    "describe2QuestionList = ['Overall Health: Everyday Activities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for question in describe2QuestionList:\n",
    "    for i in range(0,len(longCovidDf)):\n",
    "        answer = longCovidDf.loc[i,question]\n",
    "        answer = checkObstain(answer)\n",
    "        if (answer in describe2OptionList):\n",
    "            longCovidDf.loc[i,question] = describe2Map[answer]\n",
    "        else:\n",
    "            longCovidDf.loc[i,question] = answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already Scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalarOptionsList = range(0,11)\n",
    "scalarQuestionList = ['Living Situation: People Under 18', 'Living Situation: How Many People','Overall Health: Average Pain 7 Days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for question in scalarQuestionList:\n",
    "    for i in range(0,len(longCovidDf)):\n",
    "        answer = longCovidDf.loc[i,question]\n",
    "        answer = checkObstain(answer)\n",
    "        if longCovidDf.loc[i,question] == '6 or more household members under the age of 18':\n",
    "            answer = 6\n",
    "        try:\n",
    "            longCovidDf.loc[i,question] = int(answer)\n",
    "            \n",
    "        except ValueError:\n",
    "            longCovidDf.loc[i,question] = np.NaN\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question: Race\n",
    "#Answers:White, Black, Hispanic, Asian, MENA, NHPI, None of These, Prefer not to answer, Skip\n",
    "#change to 3 Variables: white, black, or other race. Each its own binary variable\n",
    "otherList = []\n",
    "\n",
    "#First, make a white Yes, No\n",
    "question = 'Race: What Race Ethnicity'\n",
    "otherList = otherList +[question]\n",
    "for i in range(0,len(longCovidDf)):\n",
    "    answer = longCovidDf.loc[i,question]\n",
    "    answer = checkObstain(answer)\n",
    "    if (answer == 'White'):\n",
    "        longCovidDf.loc[i,question] = 1\n",
    "    else:\n",
    "        longCovidDf.loc[i,question] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question:Recreation Drug Use: Which Drugs Used\n",
    "#Answers: Cocain, Prescription Opiods, Marijuana, Prefer Not Answer, None of These Drugs, \n",
    "    #Inhalants, Hallucinogens, Other, Sedatives, Prescription Stimulants, Methamphetamine, Street Opiods, Skip\n",
    "#Make this 2 binary options: Prescription drugs (y/n) and Non-perscription drugs(y/n)\n",
    "\n",
    "#First, Make a simple Yes/No for all Drugs\n",
    "\n",
    "question = 'Recreational Drug Use: Which Drugs Used'\n",
    "otherList = otherList +[question]\n",
    "for i in range(0,len(longCovidDf)):\n",
    "    answer = longCovidDf.loc[i,question]\n",
    "    answer = checkObstain(answer)\n",
    "    if (answer == 'None of These Drugs'):\n",
    "        longCovidDf.loc[i,question] = 0\n",
    "    else:\n",
    "        longCovidDf.loc[i,question] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question:Sexual Orientation\n",
    "#Answers:Straight, Bisexual, Gay, Lesbian, None, Skip, Prefer Not TO Answer\n",
    "\n",
    "#Make different variables for LGBTQ+ and straight\n",
    "#Start with straight Y/N\n",
    "\n",
    "question = 'The Basics: Sexual Orientation'\n",
    "otherList = otherList +[question]\n",
    "for i in range(0,len(longCovidDf)):\n",
    "    answer = longCovidDf.loc[i,question]\n",
    "    answer = checkObstain(answer)\n",
    "    if (answer == 'Straight'):\n",
    "        longCovidDf.loc[i,question] = 1\n",
    "    else:\n",
    "        longCovidDf.loc[i,question] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question:Annual Income\n",
    "#Answers:Less than 10K, 10K - 25K, 25K-35K, 35K-50K, 50K-75K, 75K-100K, 100K-150K, 150K-200K, More than 200K, \n",
    "    #Prefer not to answer, Skip, \n",
    "    \n",
    "#Make a 1-9 scalar\n",
    "\n",
    "question = 'Income: Annual Income'\n",
    "otherList = otherList+[question]\n",
    "\n",
    "incomeOptionList = ['less 10k', '75k 100k',\n",
    " '35k 50k', 'more 200k',\n",
    " '10k 25k', '100k 150k',\n",
    " '25k 35k', '50k 75k',\n",
    " '150k 200k']\n",
    "\n",
    "incomeMap = {'less 10k':0, '10k 25k':1, '25k 35k': 2, '35k 50k':3, '50k 75k':4, '75k 100k':5, '100k 150k':6, '150k 200k':7, 'more 200k':8}\n",
    "\n",
    "for i in range(0,len(longCovidDf)):\n",
    "        answer = longCovidDf.loc[i,question]\n",
    "        answer = checkObstain(answer)\n",
    "        if (answer in incomeOptionList):\n",
    "            longCovidDf.loc[i,question] = incomeMap[answer]\n",
    "        else:\n",
    "            longCovidDf.loc[i,question] = answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question:Current Marital Status\n",
    "#Answers:Never Married, Married, Living With Partner, Divorced, Seperated, Widowed, Skip, Prefer Not Answer\n",
    "#Make 2 binary variables \"Ever Been Married\" and \"Currently married\"\n",
    "\n",
    "#Start with \"have you been married\"\n",
    "question = 'Marital Status: Current Marital Status'\n",
    "otherList = otherList+[question]\n",
    "\n",
    "marriageOptionList=[ 'Never Married', 'Married',\n",
    " 'Living With Partner',\n",
    " 'Divorced', 'Separated',\n",
    " 'Widowed']\n",
    "\n",
    "marriageMap = {'Never Married':0, 'Married':1, 'Living With Partner': 0, 'Divorced':1, 'Widowed':1, 'Separated':1}\n",
    "\n",
    "for i in range(0,len(longCovidDf)):\n",
    "        answer = longCovidDf.loc[i,question]\n",
    "        answer = checkObstain(answer)\n",
    "        if (answer in marriageOptionList):\n",
    "            longCovidDf.loc[i,question] = marriageMap[answer]\n",
    "        else:\n",
    "            longCovidDf.loc[i,question] = answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question:Alchohol: Drink Frequency Past Year\n",
    "#Answers: Never, Monthly or Less, 2 to 4 per month, 2 to 3 per week, 4 or more per week, Prefer Not to Answer, Skip\n",
    "#Make 0-4 scalar\n",
    "\n",
    "question = 'Alcohol: Drink Frequency Past Year'\n",
    "otherList = otherList+[question]\n",
    "\n",
    "alcoholOptionList = ['Monthly Or Less',\n",
    " '4 or More Per Week',\n",
    " '2 to 4 Per Month',\n",
    " '2 to 3 Per Week',\n",
    " 'Never']\n",
    "\n",
    "alcoholMap = {'Never':0, 'Monthly Or Less':1, '2 to 4 Per Month': 2, '2 to 3 Per Week':3, '4 or More Per Week':4}\n",
    "\n",
    "for i in range(0,len(longCovidDf)):\n",
    "        answer = longCovidDf.loc[i,question]\n",
    "        answer = checkObstain(answer)\n",
    "        if (answer in alcoholOptionList):\n",
    "            longCovidDf.loc[i,question] = alcoholMap[answer]\n",
    "        else:\n",
    "            longCovidDf.loc[i,question] = answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question: Employment Status\n",
    "#Answers: Out of Work/Less than One, Employed for Wages, Retired, Unable to Work, Student, Self Employed\n",
    "#Out of Work /One or More, Homemaker, Skip, Prefer Not Answer\\\n",
    "#Make Binary Variable \"Working or not\"\n",
    "\n",
    "question = 'Employment: Employment Status'\n",
    "otherList = otherList +[question]\n",
    "workingList = ['Self Employed', 'Employed for Wages']\n",
    "\n",
    "for i in range(0,len(longCovidDf)):\n",
    "    answer = longCovidDf.loc[i,question]\n",
    "    answer = checkObstain(answer)\n",
    "    if (answer in workingList):\n",
    "        longCovidDf.loc[i,question] = 1\n",
    "    else:\n",
    "        longCovidDf.loc[i,question] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question:Living Situation: How Many YEars\n",
    "#Answers:less than 1, 1 to 2, 3 to 5, 6 to 10, 11 to 20, more than 20, skip\n",
    "#Make a 0-5 scalar\n",
    "\n",
    "question = 'Living Situation: How Many Living Years'\n",
    "otherList = otherList+[question]\n",
    "\n",
    "livingOptionList = ['less 1', '3 to 5',\n",
    " '11 to 20', 'more 20',\n",
    " '6 to 10', '1 to 2']\n",
    "\n",
    "livingMap = {'less 1':0, '1 to 2':1, '3 to 5': 2, '6 to 10':3, '11 to 20':4, 'more 20':5}\n",
    "\n",
    "for i in range(0,len(longCovidDf)):\n",
    "        answer = longCovidDf.loc[i,question]\n",
    "        answer = checkObstain(answer)\n",
    "        if (answer in livingOptionList):\n",
    "            longCovidDf.loc[i,question] = livingMap[answer]\n",
    "        else:\n",
    "            longCovidDf.loc[i,question] = answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question:Education Level: Highest Grade\n",
    "#Answers:Twelve or GED, Advanced Degree, College One to Three, Five Through Eight, Nine Throigh Eleven, College Graduate, \n",
    "#Prefer Not Answer, Skip, Never Attended, One through Four\n",
    "\n",
    "#Use Scalar\n",
    "\n",
    "question = 'Education Level: Highest Grade'\n",
    "otherList = otherList+[question]\n",
    "\n",
    "eduOptionList = ['Twelve Or GED',\n",
    "                 'Advanced Degree', 'College One to Three', 'Five Through Eight', 'Nine Through Eleven',\n",
    "                 'College Graduate', 'Never Attended','One Through Four']\n",
    "\n",
    "eduMap = education7map\n",
    "\n",
    "for i in range(0,len(longCovidDf)):\n",
    "        answer = longCovidDf.loc[i,question]\n",
    "        answer = checkObstain(answer)\n",
    "        if (answer in eduOptionList):\n",
    "            longCovidDf.loc[i,question] = eduMap[answer]\n",
    "        else:\n",
    "            longCovidDf.loc[i,question] = answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to take each of these questions and make an answer for them that is some form of scalar. This may Take Some time.\n",
    "#A good way might be to make a loop given the \"important questions\" data frame to look at the unique entries of each\n",
    "for question in surveyDf['question'].unique():\n",
    "    if(question in ['Overall Health: Average Pain 7 Days']):\n",
    "        print(question)\n",
    "        thisQuestionDf = surveyDf[surveyDf['question']==question]\n",
    "        print(thisQuestionDf['answer'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericList = binaryQuestionList+describeQuestionList+describe2QuestionList+severeQuestionList+scalarQuestionList+oftenQuestionList+goodQuestionList+['long_covid', 'person_id']+otherList\n",
    "#numericList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trialDf=longCovidDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nanList = []\n",
    "for a in range(0,len(trialDf)):\n",
    "    if (trialDf.loc[a,'y_pred'] >=0):\n",
    "        #do nothing\n",
    "        x=1\n",
    "    else:\n",
    "        nanList = nanList + [a]\n",
    "        print(a, trialDf.loc[a,'y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in nanList:\n",
    "    trialDf.loc[a,'y_pred'] = 0.40883501377605025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are targetVariables and y_pred variables that are 'too large to be float 64. Try to find them and see what it is\n",
    "for i in range(0,len(trialDf)):\n",
    "    if (float(trialDf.loc[i,'y_pred'])<= 1):\n",
    "        x=1\n",
    "    else:\n",
    "        print(trialDf.loc[i,'y_pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find where the code is giving non-numeric outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print Unique values for some of the columns. If nothing turns up, then make an iterative try-catch loop to find non-numerics\n",
    "for a in trialDf.columns:\n",
    "    if type(trialDf.loc[1,a]) in [float, int, np.int64, np.float64]:\n",
    "        x=1\n",
    "    else:\n",
    "        print (a)\n",
    "        print(trialDf[a].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trialDf = trialDf.drop(['Health Insurance: Health Insurance Type', 'Health Insurance: Insurance Type Update', 'Gender: Gender Identity'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Make a big loop to check all the answers, and hope it doesn't take forever\n",
    "for col in trialDf.columns:\n",
    "    for row in range(0,len(trialDf)):\n",
    "        trialDf.loc[row,col] = checkObstain(trialDf.loc[row,col])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trialDf = trialDf.replace('NaN', np.NaN)\n",
    "trialDf = trialDf.replace('nan', np.NaN)\n",
    "for a in trialDf.columns:\n",
    "    #columnDf = trialDf[a]\n",
    "    columnMean = trialDf.loc[trialDf[a].isin(range(0,100)),a].mean()\n",
    "    #print(a)\n",
    "    #print(columnMean)\n",
    "    trialDf[a] = trialDf[a].fillna(value = columnMean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Df using google bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#trialDf=trialDf.drop(['index'] ,axis=1)\n",
    "trialDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataframe = trialDf   \n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to store in the bucket (don't delete the quotation marks)\n",
    "destination_filename = 'SurveyDataJuly2023.csv'\n",
    "\n",
    "########################################################################\n",
    "##\n",
    "################# DON'T CHANGE FROM HERE ###############################\n",
    "##\n",
    "########################################################################\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "# print output from gsutil\n",
    "output.stderr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#........."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
