{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = %env WORKSPACE_CDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "name_of_file_in_bucket = 'n3c_aou_cohort.csv'\n",
    "\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file from the bucket to the current working space\n",
    "os.system(f\"gsutil cp '{my_bucket}/data/{name_of_file_in_bucket}' .\")\n",
    "\n",
    "print(f'[INFO] {name_of_file_in_bucket} is successfully downloaded into your working space')\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "cohort = pd.read_csv(name_of_file_in_bucket)\n",
    "cohort.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['Activity summary', 'Minulte-level heart rate', 'Heart rate summary', 'Steps intraday']\n",
    "tables = ['activity_summary', 'heart_rate_minute_level', 'heart_rate_summary', 'steps_intraday', 'sleep_level', 'sleep_daily_summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cohort = pd.read_csv('n3c_aou_cohort.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "name_of_file_in_bucket = 'n3c_aou_cohort_ft.csv'\n",
    "\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file from the bucket to the current working space\n",
    "os.system(f\"gsutil cp '{my_bucket}/data/{name_of_file_in_bucket}' .\")\n",
    "\n",
    "print(f'[INFO] {name_of_file_in_bucket} is successfully downloaded into your working space')\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "cohort_with_covid_dt = pd.read_csv(name_of_file_in_bucket)\n",
    "cohort_with_covid_dt.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_with_covid_dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_with_covid_dt = cohort_with_covid_dt.merge(cohort[['person_id']], left_on='person_id', right_on='person_id',\n",
    "          suffixes=('_left', '_right'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_with_covid_dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(cohort_with_covid_dt['min_covid_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = tuple(cohort['person_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_50 = tuple(list(cohort['person_id'])[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(people_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_summary_sql = f\"\"\"select * from `{dataset}`.activity_summary where person_id in {people} \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_summary_df = pd.read_gbq(steps_summary_sql, dialect=\"standard\", use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),  progress_bar_type=\"tqdm_notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_summary_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_summary_df['date']= pd.to_datetime(steps_summary_df['date'])\n",
    "\n",
    "cohort_with_covid_dt['min_covid_dt'] = pd.to_datetime(cohort_with_covid_dt['min_covid_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from statistics import median\n",
    "\n",
    "steps_stat = []\n",
    "\n",
    "for index, row in cohort_with_covid_dt.iterrows():\n",
    "    person_id = row['person_id']\n",
    "    min_covid_dt = row['min_covid_dt']\n",
    "    \n",
    "    min_covid_dt_minus_7 = min_covid_dt - relativedelta(days=7)\n",
    "    min_covid_dt_plus_28 = min_covid_dt + relativedelta(days=28)\n",
    "    \n",
    "    p_data = steps_summary_df[steps_summary_df['person_id'] == person_id]\n",
    "    \n",
    "    p_data['date']= pd.to_datetime(p_data['date'])\n",
    "    \n",
    "    \n",
    "    if not p_data.empty:\n",
    "        \n",
    "        prev_df = p_data[(p_data['date'] < min_covid_dt_minus_7)]\n",
    "        next_df = p_data[p_data['date'] > min_covid_dt_plus_28]\n",
    "        \n",
    "        prev_steps = list(prev_df['steps'])\n",
    "\n",
    "        prev_steps.sort()\n",
    "\n",
    "        next_steps = list(next_df['steps'])\n",
    "\n",
    "        next_steps.sort()\n",
    "\n",
    "        p_m = 0\n",
    "        n_m = 0\n",
    "\n",
    "        if len(prev_steps) > 0:\n",
    "            p_m = median(prev_steps)\n",
    "\n",
    "        if len(next_steps) > 0:\n",
    "            n_m = median(next_steps)\n",
    "\n",
    "\n",
    "        steps_stat.append([person_id, min_covid_dt, p_m, n_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_stat_df = pd.DataFrame(steps_stat, columns=['person_id', 'min_covid_dt', 'before_covid_median_steps', 'after_covid_median_steps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_stat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_filename = 'steps_median.csv'\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "steps_stat_df.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "# print output from gsutil\n",
    "output.stderr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps_stat_df.to_csv('steps_median.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrml_sql = f\"\"\"select person_id, date(datetime) as date, avg(heart_rate_value) as average_heart_rate from `{dataset}`.heart_rate_minute_level where person_id in {people} group by 1,2\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrml_df = pd.read_gbq(hrml_sql, dialect=\"standard\", use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),  progress_bar_type=\"tqdm_notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrml_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from statistics import median\n",
    "\n",
    "heart_rate_minute_level_stat = []\n",
    "\n",
    "for index, row in cohort_with_covid_dt.iterrows():\n",
    "    person_id = row['person_id']\n",
    "    min_covid_dt = row['min_covid_dt']\n",
    "      \n",
    "    min_covid_dt_minus_7 = min_covid_dt - relativedelta(days=7)\n",
    "    min_covid_dt_plus_28 = min_covid_dt + relativedelta(days=28)\n",
    "    \n",
    "    p_data = hrml_df[hrml_df['person_id'] == person_id]\n",
    "    \n",
    "    p_data['date']= pd.to_datetime(p_data['date'])\n",
    "    \n",
    "    \n",
    "    if not p_data.empty:\n",
    "        \n",
    "        prev_df = p_data[p_data['date'] < min_covid_dt_minus_7]\n",
    "        next_df = p_data[p_data['date'] > min_covid_dt_plus_28]\n",
    "        prev_hr = list(prev_df['average_heart_rate'])\n",
    "\n",
    "        prev_hr.sort()\n",
    "\n",
    "        next_hr = list(next_df['average_heart_rate'])\n",
    "\n",
    "        next_hr.sort()\n",
    "\n",
    "        p_m = 0\n",
    "        n_m = 0\n",
    "\n",
    "        if len(prev_hr) > 0:\n",
    "            p_m = median(prev_hr)\n",
    "\n",
    "        if len(next_hr) > 0:\n",
    "            n_m = median(next_hr)\n",
    "\n",
    "\n",
    "        heart_rate_minute_level_stat.append([person_id, min_covid_dt, p_m, n_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_rate_minute_level_df = pd.DataFrame(heart_rate_minute_level_stat, columns=['person_id', 'min_covid_dt', 'before_covid_avg_heart_rate', 'after_covid_avg_heart_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_filename = 'avg_heart_rate_median.csv'\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "heart_rate_minute_level_df.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "# print output from gsutil\n",
    "output.stderr\n",
    "\n",
    "\n",
    "#heart_rate_minute_level_df.to_csv('avg_heart_rate_median.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_summary_sql = f\"\"\"select * from `{dataset}`.heart_rate_summary where person_id in {people} \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_summary_df = pd.read_gbq(hr_summary_sql, dialect=\"standard\", use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),  progress_bar_type=\"tqdm_notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from statistics import median\n",
    "\n",
    "heart_rate_min_max_stat = []\n",
    "\n",
    "for index, row in cohort_with_covid_dt.iterrows():\n",
    "    person_id = row['person_id']\n",
    "    min_covid_dt = row['min_covid_dt']\n",
    "     \n",
    "    min_covid_dt_minus_7 = min_covid_dt - relativedelta(days=7)\n",
    "    min_covid_dt_plus_28 = min_covid_dt + relativedelta(days=28)\n",
    "    \n",
    "    p_data = hr_summary_df[hr_summary_df['person_id'] == person_id]\n",
    "    \n",
    "    p_data['date']= pd.to_datetime(p_data['date'])\n",
    "    \n",
    "    \n",
    "    if not p_data.empty:\n",
    "        \n",
    "        prev_df = p_data[p_data['date'] < min_covid_dt_minus_7]\n",
    "        next_df = p_data[p_data['date'] > min_covid_dt_plus_28 ]\n",
    "        \n",
    "        prev_min_hr = list(prev_df['min_heart_rate'])\n",
    "        prev_max_hr = list(prev_df['max_heart_rate'])\n",
    "\n",
    "        prev_min_hr.sort()\n",
    "        prev_max_hr.sort()\n",
    "\n",
    "        next_min_hr = list(next_df['min_heart_rate'])\n",
    "        next_max_hr = list(next_df['max_heart_rate'])\n",
    "\n",
    "        next_min_hr.sort()\n",
    "        next_max_hr.sort()\n",
    "\n",
    "        p_m = 0\n",
    "        n_m = 0\n",
    "\n",
    "        if len(prev_min_hr) > 0:\n",
    "            p_min_m = median(prev_min_hr)\n",
    "            \n",
    "        if len(prev_max_hr) > 0:\n",
    "            p_max_m = median(prev_max_hr)\n",
    "\n",
    "        if len(next_min_hr) > 0:\n",
    "            n_min_m = median(next_min_hr)\n",
    "            \n",
    "        if len(next_max_hr) > 0:\n",
    "            n_max_m = median(next_max_hr)    \n",
    "\n",
    "\n",
    "        heart_rate_min_max_stat.append([person_id, min_covid_dt, p_min_m, p_max_m, n_min_m, n_max_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_rate_min_max_df = pd.DataFrame(heart_rate_min_max_stat, columns=['person_id', 'min_covid_dt', 'before_covid_min_heart_rate', 'before_covid_max_heart_rate', 'after_covid_min_heart_rate', 'after_covid_max_heart_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_rate_min_max_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_filename = 'heart_rate_min_max_median.csv'\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "heart_rate_min_max_df.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "\n",
    "#heart_rate_min_max_df.to_csv('heart_rate_min_max_median.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_level_sql = f\"\"\"select * from `{dataset}`.sleep_level where person_id in {people}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_level_df = pd.read_gbq(sleep_level_sql, dialect=\"standard\", use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),  progress_bar_type=\"tqdm_notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_level_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_summary_sql = f\"\"\"select * from `{dataset}`.sleep_daily_summary where person_id in {people} \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_summary_df = pd.read_gbq(sleep_summary_sql, dialect=\"standard\", use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),  progress_bar_type=\"tqdm_notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from statistics import median\n",
    "\n",
    "sleep_summary_stat = []\n",
    "\n",
    "for index, row in cohort_with_covid_dt.iterrows():\n",
    "    person_id = row['person_id']\n",
    "    min_covid_dt = row['min_covid_dt']\n",
    "    \n",
    "    min_covid_dt_minus_7 = min_covid_dt - relativedelta(days=7)\n",
    "    min_covid_dt_plus_28 = min_covid_dt + relativedelta(days=28)\n",
    "    \n",
    "    p_data = sleep_summary_df[sleep_summary_df['person_id'] == person_id]\n",
    "    \n",
    "    p_data['sleep_date']= pd.to_datetime(p_data['sleep_date'])\n",
    "    \n",
    "    \n",
    "    if not p_data.empty:\n",
    "        \n",
    "        prev_df = p_data[p_data['sleep_date'] < min_covid_dt_minus_7]\n",
    "        next_df = p_data[p_data['sleep_date'] > min_covid_dt_plus_28]\n",
    "        \n",
    "        prev_hr = list(prev_df['minute_asleep'])\n",
    "\n",
    "        prev_hr.sort()\n",
    "\n",
    "        next_hr = list(next_df['minute_asleep'])\n",
    "\n",
    "        next_hr.sort()\n",
    "\n",
    "        p_m = 0\n",
    "        n_m = 0\n",
    "\n",
    "        if len(prev_hr) > 0:\n",
    "            p_m = median(prev_hr)\n",
    "\n",
    "        if len(next_hr) > 0:\n",
    "            n_m = median(next_hr)\n",
    "\n",
    "\n",
    "        sleep_summary_stat.append([person_id, min_covid_dt, p_m, n_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_summary_stat_df = pd.DataFrame(sleep_summary_stat, columns=['person_id', 'min_covid_dt', 'before_covid_median_minutes_asleep', 'after_covid_median_minutes_asleep'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_filename = 'sleep_summary_stat_df.csv'\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "sleep_summary_stat_df.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "#sleep_summary_stat_df.to_csv('sleep_summary_stat_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_summary_df[sleep_summary_df['person_id'] == 2114885]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitbit_wore_time_sql = f\"\"\"SELECT person_id, date, SUM(has_hour) AS hours_with_fitbit FROM (SELECT person_id, CAST(datetime AS DATE) AS date, IF(SUM(steps)>0, 1, 0) AS has_hour FROM `{dataset}`.steps_intraday where person_id in {people} GROUP BY CAST(datetime AS DATE), EXTRACT(HOUR FROM datetime), person_id) t GROUP BY date, person_id\"\"\"\n",
    "\n",
    "fitbit_wore_time_df = pd.read_gbq(fitbit_wore_time_sql, dialect=\"standard\", use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),  progress_bar_type=\"tqdm_notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitbit_wore_time_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_with_covid_dt['min_covid_dt']= pd.to_datetime(cohort_with_covid_dt['min_covid_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from statistics import median\n",
    "\n",
    "wear_time_stat = []\n",
    "\n",
    "for index, row in cohort_with_covid_dt.iterrows():\n",
    "    person_id = row['person_id']\n",
    "    min_covid_dt = row['min_covid_dt']\n",
    "    \n",
    "    min_covid_dt_minus_7 = min_covid_dt - relativedelta(days=7)\n",
    "    min_covid_dt_plus_28 = min_covid_dt + relativedelta(days=28)\n",
    "    \n",
    "    p_data = fitbit_wore_time_df[fitbit_wore_time_df['person_id'] == person_id]\n",
    "    \n",
    "    p_data['date']= pd.to_datetime(p_data['date'])\n",
    "    \n",
    "    \n",
    "    if not p_data.empty:\n",
    "        \n",
    "        prev_df = p_data[(p_data['date'] < min_covid_dt_minus_7)]\n",
    "        next_df = p_data[p_data['date'] > min_covid_dt_plus_28]\n",
    "        \n",
    "        prev_steps = list(prev_df['hours_with_fitbit'])\n",
    "\n",
    "        prev_steps.sort()\n",
    "\n",
    "        next_steps = list(next_df['hours_with_fitbit'])\n",
    "\n",
    "        next_steps.sort()\n",
    "\n",
    "        p_m = 0\n",
    "        n_m = 0\n",
    "\n",
    "        if len(prev_steps) > 0:\n",
    "            p_m = median(prev_steps)\n",
    "\n",
    "        if len(next_steps) > 0:\n",
    "            n_m = median(next_steps)\n",
    "\n",
    "\n",
    "        wear_time_stat.append([person_id, min_covid_dt, p_m, n_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wear_time_median_df = pd.DataFrame(wear_time_stat, columns=['person_id', 'min_covid_dt', 'before_covid_median_wear_time', 'after_covid_median_wear_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_filename = 'median_weartime_before_after_longcovid.csv'\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "wear_time_median_df.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "#wear_time_median_df.to_csv('median_weartime_before_after_longcovid.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_filename = 'fitbit_wore_time_df.csv'\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "fitbit_wore_time_df.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "#fitbit_wore_time_df.to_csv('fitbit_wore_time_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitbit_wore_time_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from statistics import median\n",
    "\n",
    "fitbit_weartime_stat = []\n",
    "\n",
    "for index, row in cohort_with_covid_dt.iterrows():\n",
    "    person_id = row['person_id']\n",
    "    min_covid_dt = row['min_covid_dt']\n",
    "    \n",
    "    \n",
    "    p_data = fitbit_wore_time_df[fitbit_wore_time_df['person_id'] == person_id]\n",
    "    \n",
    "    p_data['date']= pd.to_datetime(p_data['date'])\n",
    "    \n",
    "    \n",
    "    if not p_data.empty:\n",
    "        \n",
    "        avg_weartime = list(p_data['hours_with_fitbit'])\n",
    "        avg_wt = round(sum(avg_weartime)/len(avg_weartime), 2)\n",
    "\n",
    "\n",
    "        fitbit_wore_time_df.append([person_id, min_covid_dt, avg_wt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitbit_wore_time_stat_df = pd.DataFrame(fitbit_wore_time_df, columns=['person_id', 'min_covid_dt', 'avg_weartime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitbit_wore_time_stat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitbit_wore_time_sql = f\"\"\"SELECT person_id, AVG(hours_with_fitbit) as average_weartime from\n",
    "(SELECT person_id, date, SUM(has_hour) AS hours_with_fitbit FROM (SELECT person_id, CAST(datetime AS DATE) AS date, \n",
    "IF(SUM(steps)>0, 1, 0) AS has_hour FROM `{dataset}`.steps_intraday where person_id in {people} GROUP BY CAST(datetime AS DATE), EXTRACT(HOUR FROM datetime), person_id) t GROUP BY date, person_id)\n",
    "GROUP BY person_id\"\"\"\n",
    "\n",
    "fitbit_wore_time_df = pd.read_gbq(fitbit_wore_time_sql, dialect=\"standard\", use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),  progress_bar_type=\"tqdm_notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitbit_wore_time_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_filename = 'fitbit_avg_weartime.csv'\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "fitbit_wore_time_df.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "#fitbit_wore_time_df.to_csv('fitbit_avg_weartime.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['Activity summary', 'Minulte-level heart rate', 'Heart rate summary', 'Steps intraday']\n",
    "tables = ['activity_summary', 'heart_rate_minute_level', 'heart_rate_summary', 'steps_intraday', 'sleep_level', 'sleep_daily_summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl_sql = f\"\"\"SELECT * from `{dataset}`.activity_summary limit 1000\"\"\"\n",
    "\n",
    "expl_df = pd.read_gbq(expl_sql, dialect=\"standard\", use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),  progress_bar_type=\"tqdm_notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl_sql = f\"\"\"SELECT * from `{dataset}`.heart_rate_summary limit 1000\"\"\"\n",
    "\n",
    "expl_df = pd.read_gbq(expl_sql, dialect=\"standard\", use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),  progress_bar_type=\"tqdm_notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl_sql = f\"\"\"SELECT *\n",
    "from `{dataset}`.heart_rate_minute_level where person_id in {people} limit 1000\"\"\"\n",
    "\n",
    "expl_df = pd.read_gbq(expl_sql, dialect=\"standard\", use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),  progress_bar_type=\"tqdm_notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_rate_minute_level_median_sql = f\"\"\"SELECT DISTINCT person_id, date(datetime) as date, PERCENTILE_DISC(heart_rate_value, 0.5) OVER (PARTITION BY person_id, date(datetime)) as median_heart_rate\n",
    "from `{dataset}`.heart_rate_minute_level where person_id in {people} \"\"\"\n",
    "\n",
    "heart_rate_minute_level_median_df = pd.read_gbq(heart_rate_minute_level_median_sql, dialect=\"standard\", use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),  progress_bar_type=\"tqdm_notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_rate_minute_level_median_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_rate_minute_level_median_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from statistics import median\n",
    "\n",
    "hrml_median_stat = []\n",
    "\n",
    "cohort_with_covid_dt['min_covid_dt'] = pd.to_datetime(cohort_with_covid_dt['min_covid_dt'])\n",
    "\n",
    "for index, row in cohort_with_covid_dt.iterrows():\n",
    "    person_id = row['person_id']\n",
    "    min_covid_dt = row['min_covid_dt']\n",
    "    \n",
    "    min_covid_dt_minus_7 = min_covid_dt - relativedelta(days=7)\n",
    "    min_covid_dt_plus_28 = min_covid_dt + relativedelta(days=28)\n",
    "    \n",
    "    p_data = heart_rate_minute_level_median_df[heart_rate_minute_level_median_df['person_id'] == person_id]\n",
    "    \n",
    "    p_data['date']= pd.to_datetime(p_data['date'])\n",
    "    \n",
    "    \n",
    "    if not p_data.empty:\n",
    "        \n",
    "        prev_df = p_data[(p_data['date'] < min_covid_dt_minus_7)]\n",
    "        next_df = p_data[p_data['date'] > min_covid_dt_plus_28]\n",
    "        \n",
    "        prev_steps = list(prev_df['median_heart_rate'])\n",
    "\n",
    "        prev_steps.sort()\n",
    "\n",
    "        next_steps = list(next_df['median_heart_rate'])\n",
    "\n",
    "        next_steps.sort()\n",
    "\n",
    "        p_m = 0\n",
    "        n_m = 0\n",
    "\n",
    "        if len(prev_steps) > 0:\n",
    "            p_m = median(prev_steps)\n",
    "\n",
    "        if len(next_steps) > 0:\n",
    "            n_m = median(next_steps)\n",
    "\n",
    "\n",
    "        hrml_median_stat.append([person_id, min_covid_dt, p_m, n_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrml_median_stat_df = pd.DataFrame(hrml_median_stat, columns=['person_id', 'min_covid_dt', 'heart_rate_median_before_covid', 'heart_rate_median_after_covid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_filename = 'heart_rate_minute_level_median.csv'\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "hrml_median_stat_df.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "#hrml_median_stat_df.to_csv('heart_rate_minute_level_median.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_summary_sql = f\"\"\"SELECT * from `{dataset}`.sleep_daily_summary where person_id in {people} \"\"\"\n",
    "\n",
    "sleep_summary_df = pd.read_gbq(sleep_summary_sql, dialect=\"standard\", use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),  progress_bar_type=\"tqdm_notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from statistics import median\n",
    "\n",
    "dsm_stat = []\n",
    "\n",
    "cohort_with_covid_dt['min_covid_dt'] = pd.to_datetime(cohort_with_covid_dt['min_covid_dt'])\n",
    "\n",
    "sleep_summary_df['minute_asleep'] = sleep_summary_df['minute_asleep'].fillna(0)\n",
    "\n",
    "for index, row in cohort_with_covid_dt.iterrows():\n",
    "    person_id = row['person_id']\n",
    "    min_covid_dt = row['min_covid_dt']\n",
    "    \n",
    "    min_covid_dt_minus_7 = min_covid_dt - relativedelta(days=7)\n",
    "    min_covid_dt_plus_28 = min_covid_dt + relativedelta(days=28)\n",
    "    \n",
    "    p_data = sleep_summary_df[sleep_summary_df['person_id'] == person_id]\n",
    "    \n",
    "    p_data['sleep_date']= pd.to_datetime(p_data['sleep_date'])\n",
    "    \n",
    "    \n",
    "    if not p_data.empty:\n",
    "        \n",
    "        prev_df = p_data[(p_data['sleep_date'] < min_covid_dt_minus_7)]\n",
    "        next_df = p_data[p_data['sleep_date'] > min_covid_dt_plus_28]\n",
    "        \n",
    "        prev_steps = list(prev_df['minute_asleep'])\n",
    "\n",
    "        prev_steps.sort()\n",
    "\n",
    "        next_steps = list(next_df['minute_asleep'])\n",
    "\n",
    "        next_steps.sort()\n",
    "\n",
    "        p_m = 0\n",
    "        n_m = 0\n",
    "\n",
    "        if len(prev_steps) > 0:\n",
    "            p_m = median(prev_steps)\n",
    "\n",
    "        if len(next_steps) > 0:\n",
    "            n_m = median(next_steps)\n",
    "\n",
    "\n",
    "        dsm_stat.append([person_id, min_covid_dt, p_m, n_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsm_stat_df = pd.DataFrame(dsm_stat, columns=['person_id', 'min_covid_dt', 'asleep_min_median_before_covid', 'asleep_min_median_after_covid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_filename = 'asleep_minutes_median.csv'\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "dsm_stat_df.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "#dsm_stat_df.to_csv('asleep_minutes_median.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsm_stat_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
